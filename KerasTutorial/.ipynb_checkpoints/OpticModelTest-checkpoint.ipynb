{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\00_data\\pycharmprojects\\opticjupyter\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\00_data\\pycharmprojects\\opticjupyter\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\00_data\\pycharmprojects\\opticjupyter\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\00_data\\pycharmprojects\\opticjupyter\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\00_data\\pycharmprojects\\opticjupyter\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\00_data\\pycharmprojects\\opticjupyter\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from functools import reduce\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers import Convolution2D, MaxPooling2D\n",
    "# from keras.utils import np_utils\n",
    "# from keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class yolo_eval_layer(keras.layers.Layer):\n",
    "    def __init__(self, anchors, num_classes, image_shape, max_boxes=20, score_threshold=.6, iou_threshold=.5, **kwargs):\n",
    "        self.boxes_ = []\n",
    "        self.scores_ = []\n",
    "        self.classes_ = []\n",
    "        self.anchors = anchors\n",
    "        self.num_classes = num_classes\n",
    "        self.image_shape = image_shape\n",
    "        self.max_boxes = max_boxes\n",
    "        self.score_threshold = score_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        super(yolo_eval_layer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(yolo_eval_layer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        num_layers = len(inputs)\n",
    "        anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5],\n",
    "                                                                                 [1, 2, 3]]  # default setting\n",
    "        input_shape = K.shape(inputs[0])[1:3] * 32\n",
    "        boxes = []\n",
    "        box_scores = []\n",
    "        for l in range(num_layers):\n",
    "            _boxes, _box_scores = yolo_boxes_and_scores(inputs[l],\n",
    "                    self.anchors[anchor_mask[l]],  self.num_classes,  input_shape,  self.image_shape)\n",
    "            boxes.append(_boxes)\n",
    "            box_scores.append(_box_scores)\n",
    "        boxes = K.concatenate(boxes, axis=0)\n",
    "        box_scores = K.concatenate(box_scores, axis=0)\n",
    "\n",
    "        mask = box_scores >= self.score_threshold\n",
    "        max_boxes_tensor = K.constant(self.max_boxes, dtype='int32')\n",
    "\n",
    "        boxes_ = []\n",
    "        scores_ = []\n",
    "        classes_ = []\n",
    "        for c in range(self.num_classes):\n",
    "            # TODO: use keras backend instead of tf.\n",
    "            class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
    "            class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
    "            nms_index = tf.image.non_max_suppression(\n",
    "                class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=self.iou_threshold)\n",
    "            class_boxes = K.gather(class_boxes, nms_index)\n",
    "            class_box_scores = K.gather(class_box_scores, nms_index)\n",
    "            classes = K.ones_like(class_box_scores, 'int32') * c\n",
    "            boxes_.append(class_boxes)\n",
    "            scores_.append(class_box_scores)\n",
    "            classes_.append(classes)\n",
    "\n",
    "        # self.boxes_ = K.concatenate(boxes_, axis=0)  #\n",
    "        # self.scores_ = K.concatenate(scores_, axis=0)  #\n",
    "        # self.classes_ = K.concatenate(classes_, axis=0)  #\n",
    "        self.boxes_ = K.expand_dims(K.concatenate(boxes_, axis=0), axis=0)\n",
    "        self.scores_ = K.expand_dims(K.concatenate(scores_, axis=0), axis=0)\n",
    "        self.classes_ = K.expand_dims(K.concatenate(classes_, axis=0), axis=0)\n",
    "        return [self.boxes_, self.scores_, self.classes_]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [K.shape(self.boxes_), K.shape(self.scores_), K.shape(self.classes_)]\n",
    "        # [K.shape(2,), K.shape(1,), K.shape(1,)]\n",
    "        # [K.shape(self.boxes_), K.shape(self.scores_), K.shape(self.classes_)]\n",
    "        # [(self.num_classes, 4), (self.num_classes, 1), (self.num_classes, 1)]\n",
    "\n",
    "def convolution_block(x, filters, rows, cols, padding='same', strides=(1, 1), bias=False):\n",
    "    channel_axis = -1\n",
    "    x1 = keras.layers.Convolution2D(filters, (rows, cols), strides=strides, padding=padding, use_bias=bias)(x)\n",
    "#     tf.keras.layers.BatchNormalization()\n",
    "    x2 = keras.layers.normalization.BatchNormalization()(x1)\n",
    "    x3 = keras.layers.advanced_activations.ReLU()(x2)\n",
    "    return x3\n",
    "\n",
    "def merge_add_concat(intput_list, mode, concat_axis):\n",
    "    if mode is 'concat':\n",
    "        x = keras.layers.concatenate(intput_list, axis=concat_axis)\n",
    "    else:\n",
    "        x = keras.layers.Add()(intput_list)\n",
    "    return x\n",
    "\n",
    "def inception_stem(input_):\n",
    "    channel_axis = -1\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
    "    x = convolution_block(input_, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = convolution_block(x, 32, 3, 3, padding='valid')\n",
    "    x = convolution_block(x, 64, 3, 3)\n",
    "\n",
    "    x1 = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(x)\n",
    "    x2 = convolution_block(x, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    x = merge_add_concat([x1, x2], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    x1 = convolution_block(x, 64, 1, 1)\n",
    "    x1 = convolution_block(x1, 96, 3, 3, padding='valid')\n",
    "\n",
    "    x2 = convolution_block(x, 64, 1, 1)\n",
    "    x2 = convolution_block(x2, 64, 1, 7)\n",
    "    x2 = convolution_block(x2, 64, 7, 1)\n",
    "    x2 = convolution_block(x2, 96, 3, 3, padding='valid')\n",
    "\n",
    "    x = merge_add_concat([x1, x2], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    x1 = convolution_block(x, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x2 = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    x = merge_add_concat([x1, x2], mode='concat', concat_axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "def inception_a(input_):\n",
    "    channel_axis = -1\n",
    "\n",
    "    a1 = convolution_block(input_, 96, 1, 1)\n",
    "\n",
    "    a2 = convolution_block(input_, 64, 1, 1)\n",
    "    a2 = convolution_block(a2, 96, 3, 3)\n",
    "\n",
    "    a3 = convolution_block(input_, 64, 1, 1)\n",
    "    a3 = convolution_block(a3, 96, 3, 3)\n",
    "    a3 = convolution_block(a3, 96, 3, 3)\n",
    "\n",
    "    a4 = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input_)\n",
    "    a4 = convolution_block(a4, 96, 1, 1)\n",
    "\n",
    "    m = merge_add_concat([a1, a2, a3, a4], mode='concat', concat_axis=channel_axis)\n",
    "    return m\n",
    "\n",
    "def reduction_a(input_):\n",
    "    channel_axis = -1\n",
    "\n",
    "    r1 = convolution_block(input_, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    r2 = convolution_block(input_, 192, 1, 1)\n",
    "    r2 = convolution_block(r2, 224, 3, 3)\n",
    "    r2 = convolution_block(r2, 256, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    r3 = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input_)\n",
    "\n",
    "    m = merge_add_concat([r1, r2, r3], mode='concat', concat_axis=channel_axis)\n",
    "    return m\n",
    "\n",
    "def inception_b(input_):\n",
    "    channel_axis = -1\n",
    "\n",
    "    b1 = convolution_block(input_, 384, 1, 1)\n",
    "\n",
    "    b2 = convolution_block(input_, 192, 1, 1)\n",
    "    b2 = convolution_block(b2, 224, 1, 7)\n",
    "    b2 = convolution_block(b2, 256, 7, 1)\n",
    "\n",
    "    b3 = convolution_block(input_, 192, 1, 1)\n",
    "    b3 = convolution_block(b3, 192, 7, 1)\n",
    "    b3 = convolution_block(b3, 224, 1, 7)\n",
    "    b3 = convolution_block(b3, 224, 7, 1)\n",
    "    b3 = convolution_block(b3, 256, 1, 7)\n",
    "\n",
    "    b4 = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input_)\n",
    "    b4 = convolution_block(b4, 128, 1, 1)\n",
    "\n",
    "    m = merge_add_concat([b1, b2, b3, b4], mode='concat', concat_axis=channel_axis)\n",
    "    return m\n",
    "\n",
    "def reduction_b(input_):\n",
    "    channel_axis = -1\n",
    "\n",
    "    r1 = convolution_block(input_, 192, 1, 1)\n",
    "    r1 = convolution_block(r1, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    r2 = convolution_block(input_, 256, 1, 1)\n",
    "    r2 = convolution_block(r2, 256, 1, 7)\n",
    "    r2 = convolution_block(r2, 320, 7, 1)\n",
    "    r2 = convolution_block(r2, 320, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    r3 = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input_)\n",
    "\n",
    "    m = merge_add_concat([r1, r2, r3], mode='concat', concat_axis=channel_axis)\n",
    "    return m\n",
    "\n",
    "def inception_c(input_):\n",
    "    channel_axis = -1\n",
    "\n",
    "    c1 = convolution_block(input_, 256, 1, 1)\n",
    "\n",
    "    c2 = convolution_block(input_, 384, 1, 1)\n",
    "    c2_1 = convolution_block(c2, 256, 1, 3)\n",
    "    c2_2 = convolution_block(c2, 256, 3, 1)\n",
    "    c2 = merge_add_concat([c2_1, c2_2], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    c3 = convolution_block(input_, 384, 1, 1)\n",
    "    c3 = convolution_block(c3, 448, 3, 1)\n",
    "    c3 = convolution_block(c3, 512, 1, 3)\n",
    "    c3_1 = convolution_block(c3, 256, 1, 3)\n",
    "    c3_2 = convolution_block(c3, 256, 3, 1)\n",
    "    c3 = merge_add_concat([c3_1, c3_2], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    c4 = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input_)\n",
    "    c4 = convolution_block(c4, 256, 1, 1)\n",
    "\n",
    "    m = merge_add_concat([c1, c2, c3, c4], mode='concat', concat_axis=channel_axis)\n",
    "    return m\n",
    "\n",
    "def GlemConv2D(*args, **kwargs):\n",
    "    \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
    "    glem_conv_kwargs = {'kernel_regularizer': keras.regularizers.l2(5e-4)}\n",
    "    glem_conv_kwargs['padding'] = 'valid' if kwargs.get('strides')==(2,2) else 'same'\n",
    "    glem_conv_kwargs.update(kwargs)\n",
    "    return keras.layers.Conv2D(*args, **glem_conv_kwargs)\n",
    "\n",
    "def GlemConv2D_BN_Leaky(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(GlemConv2D(*args, **no_bias_kwargs), keras.layers.BatchNormalization(), keras.layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "def resblock_body(x, num_filters, num_blocks):\n",
    "    '''A series of resblocks starting with a downsampling Convolution2D'''\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    x = keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "    x = GlemConv2D_BN_Leaky(num_filters, (3, 3), strides=(2, 2))(x)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(GlemConv2D_BN_Leaky(num_filters//2, (1, 1)), GlemConv2D_BN_Leaky(num_filters, (3, 3)))(x)\n",
    "        x = keras.layers.Add()([x,y])\n",
    "    return x\n",
    "\n",
    "def make_trunk_model():\n",
    "    # make darknet53 trunk architecture\n",
    "    inputs = Input(shape=(None, None, 3))\n",
    "    x = GlemConv2D_BN_Leaky(32, (3, 3))(inputs)\n",
    "    x = resblock_body(x, 64, 1)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    trunk_output = resblock_body(x, 1024, 4)\n",
    "    return Model(inputs, trunk_output)\n",
    "\n",
    "def make_last_layers(x, num_filters, out_filters):\n",
    "    '''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''\n",
    "    x = compose(\n",
    "        GlemConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "        GlemConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "        GlemConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "        GlemConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "        GlemConv2D_BN_Leaky(num_filters, (1,1)))(x)\n",
    "    y = compose(GlemConv2D_BN_Leaky(num_filters*2, (3,3)), GlemConv2D(out_filters, (1,1)))(x)\n",
    "    return x, y\n",
    "\n",
    "def compose(*funcs):\n",
    "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
    "\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inception_v4(input_shape, size=20, activation='softmax'):\n",
    "    init = keras.layers.Input((input_shape[0], input_shape[1], 3))\n",
    "    x = inception_stem(init)\n",
    "    for i in range(4):\n",
    "        x = inception_a(x)\n",
    "    x = reduction_a(x)\n",
    "    for i in range(7):\n",
    "        x = inception_b(x)\n",
    "    x = reduction_b(x)\n",
    "    for i in range(3):\n",
    "        x = inception_c(x)\n",
    "#     before = x\n",
    "#     based = Model(init, before)\n",
    "\n",
    "    x = keras.layers.AveragePooling2D((8, 8))(x)\n",
    "\n",
    "    x = keras.layers.Dropout(1.0)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "\n",
    "    new_out = keras.layers.Dense(size, activation=activation)(x)\n",
    "    new_model = keras.models.Model(init, new_out, name='Inception-v4_fundus')\n",
    "    return new_model #, based\n",
    "\n",
    "def make_section2_model(trunk_model, anchors, class_names):\n",
    "    num_anchors = len(anchors) // 3\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    x, branch2_output1 = make_last_layers(trunk_model.output, 512, num_anchors * (num_classes + 5))\n",
    "\n",
    "    x = compose(GlemConv2D_BN_Leaky(256, (1, 1)), UpSampling2D(2))(x)\n",
    "    x = keras.layers.Concatenate()([x, trunk_model.layers[152].output])\n",
    "    x, branch2_output2 = make_last_layers(x, 256, num_anchors * (num_classes + 5))\n",
    "\n",
    "    # 1*1 conv를 통해 channel 수를 줄이는 계산을 한다.\n",
    "    x = compose(GlemConv2D_BN_Leaky(128, (1, 1)), UpSampling2D(2))(x)\n",
    "    x = keras.layers.Concatenate()([x, trunk_model.layers[92].output])\n",
    "    x, branch2_output3 = make_last_layers(x, 128, num_anchors * (num_classes + 5))\n",
    "\n",
    "    branch2_outputs = [branch2_output1, branch2_output2, branch2_output3]\n",
    "\n",
    "    model = keras.layers.Model(trunk_model.input, branch2_outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = create_inception_v4((640, 640))\n",
    "# x1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x21 = make_section2_model(make_trunk_model(), self.anchors, self.section2_class_names)\n",
    "# section2_out = yolo_eval_layer(self.anchors, len(self.section2_class_names), self.input_image_shape, score_threshold=self.score_threshold, iou_threshold=self.iou_threshold)(section2_model.output)\n",
    "# x2 = Model([x21.input], outputs=[*section2_out])\n",
    "# x2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x3 = create_inception_v4((640, 640), size=64, activation=\"sigmoid\")\n",
    "# x3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\00_data\\pycharmprojects\\opticjupyter\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "inputs = keras.layers.Input(shape=(None, None, 3))\n",
    "x = GlemConv2D_BN_Leaky(32, (3, 3))(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
